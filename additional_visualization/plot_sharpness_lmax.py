#!/usr/bin/env python3
"""
Create a CSV of batch sharpness and lambda max for two runs using the plaintext results
generated by training (same source as visualization/plot_results.py).

Usage (no full paths needed):
    export RESULTS=/path/to/results
    python additional_visualization/plot_sharpness_lmax.py \
        20260109_1851_28_lr0.01000_b32 \
        20260109_2004_27_lr0.01000_b8192 \
        --dataset cifar10_mlp \
        --format long \
        --output visualization/img/sharpness_lmax_0132_long.csv

Positional args:
- run1:    run folder name under the dataset (contains results.txt) OR absolute path to results.txt
- run2:    run folder name under the dataset (contains results.txt) OR absolute path to results.txt

Options:
- --dataset: dataset subfolder under $RESULTS/plaintext (default: cifar10_mlp)

Output formats:
- long: columns [step, run_id, lambda_max, batch_sharpness]
- wide: columns [step, lambda_max_run1, batch_sharpness_run1, lambda_max_run2, batch_sharpness_run2]
"""
import argparse
import os
from pathlib import Path
from typing import Tuple

import pandas as pd


COLUMN_NAMES = [
    "epoch",
    "step",
    "batch_loss",
    "full_loss",
    "lambda_max",
    "step_sharpness",
    "batch_sharpness",
    "gni",
    "total_accuracy",
]


def _load_results_txt(file_path: Path) -> pd.DataFrame:
    if not file_path.exists():
        raise FileNotFoundError(f"Missing results file: {file_path}")
    df = pd.read_csv(
        file_path,
        skiprows=4,
        sep=",",
        header=None,
        names=COLUMN_NAMES,
        na_values=["nan"],
        skipinitialspace=True,
    )
    # Keep only the needed columns
    out = df[["step", "lambda_max", "batch_sharpness"]].copy()
    # Ensure numeric
    out["step"] = pd.to_numeric(out["step"], errors="coerce")
    out["lambda_max"] = pd.to_numeric(out["lambda_max"], errors="coerce")
    out["batch_sharpness"] = pd.to_numeric(out["batch_sharpness"], errors="coerce")
    out = out.dropna(subset=["step"]).sort_values("step").drop_duplicates(subset=["step"], keep="last")
    return out


def _resolve_plaintext_runs(dataset: str, run1: str, run2: str) -> Tuple[Path, Path, str, str]:
    """Build absolute paths to results.txt for both runs using $RESULTS/plaintext.

    Returns: (file1, file2, label1, label2)
    """
    base = os.environ.get("RESULTS")
    if not base:
        raise RuntimeError("Set RESULTS to your results root (env var)")
    base_path = Path(base) / "plaintext" / dataset
    file1 = base_path / run1 / "results.txt"
    file2 = base_path / run2 / "results.txt"
    if not file1.exists():
        raise FileNotFoundError(f"Missing results.txt: {file1}")
    if not file2.exists():
        raise FileNotFoundError(f"Missing results.txt: {file2}")
    return file1, file2, run1, run2


def _resolve_run_input(dataset: str, run_or_path: str) -> Tuple[Path, str]:
    """Resolve an input (run folder name or absolute results.txt path) to (file_path, label).

    If run_or_path is an absolute path or points to an existing file/dir, use it directly.
    Otherwise, construct the path under $RESULTS/plaintext/<dataset>/<run_or_path>/results.txt.
    """
    p = Path(run_or_path)
    if p.exists():
        if p.is_file():
            if p.name != "results.txt":
                raise FileNotFoundError(f"Expected a results.txt file, got: {p}")
            return p, p.parent.name
        if p.is_dir():
            f = p / "results.txt"
            if not f.exists():
                raise FileNotFoundError(f"No results.txt found in directory: {p}")
            return f, p.name

    # Fallback to RESULTS/plaintext/<dataset>/<run>/results.txt
    base = os.environ.get("RESULTS")
    if not base:
        raise RuntimeError("Set RESULTS to your results root (env var), e.g., /home/marcwald/edge-of-stochastic-stability/results")
    base_path = Path(base) / "plaintext" / dataset
    f = base_path / run_or_path / "results.txt"
    if not f.exists():
        raise FileNotFoundError(f"Missing results.txt: {f}")
    return f, run_or_path


def to_long(df: pd.DataFrame, run_id: str) -> pd.DataFrame:
    out = df.copy()
    out["run_id"] = run_id
    return out[["step", "run_id", "lambda_max", "batch_sharpness"]]

def to_wide(df1: pd.DataFrame, df2: pd.DataFrame) -> pd.DataFrame:
    merged = pd.merge(df1[["step", "lambda_max", "batch_sharpness"]],
                      df2[["step", "lambda_max", "batch_sharpness"]],
                      on="step", how="inner", suffixes=("_run1", "_run2"))
    return merged


def main():
    parser = argparse.ArgumentParser(description="Create CSV of batch sharpness and lambda max for two runs (plaintext results)")
    parser.add_argument("run1", type=str, help="Run1 folder name (under dataset) or absolute results.txt path")
    parser.add_argument("run2", type=str, help="Run2 folder name (under dataset) or absolute results.txt path")
    parser.add_argument("--dataset", type=str, default="cifar10_mlp", help="Dataset folder under $RESULTS/plaintext (default: cifar10_mlp)")
    parser.add_argument("--max-steps", type=int, default=None, help="If set, include only up to this step")
    parser.add_argument("--format", type=str, default="long", choices=["long", "wide"], help="CSV format: long or wide")
    parser.add_argument("--output", type=str, default=None, help="Output CSV file path")

    args = parser.parse_args()

    file1, run1_label = _resolve_run_input(args.dataset, args.run1)
    file2, run2_label = _resolve_run_input(args.dataset, args.run2)
    run1_results_df = _load_results_txt(file1)
    run2_results_df = _load_results_txt(file2)

    # Apply max-steps filter
    if args.max_steps is not None:
        run1_results_df = run1_results_df[run1_results_df["step"] <= args.max_steps]
        run2_results_df = run2_results_df[run2_results_df["step"] <= args.max_steps]

    out_path = Path(args.output) if args.output else Path("visualization/img") / f"sharpness_lmax_{run1_label}_{run2_label}_{args.format}.csv"
    out_path.parent.mkdir(parents=True, exist_ok=True)

    if args.format == "long":
        long_df = pd.concat([to_long(run1_results_df, run1_label), to_long(run2_results_df, run2_label)], ignore_index=True)
        long_df.to_csv(out_path, index=False)
    else:
        wide_df = to_wide(run1_results_df, run2_results_df)
        wide_df.to_csv(out_path, index=False)

    print(f"Saved CSV to: {out_path}")


if __name__ == "__main__":
    main()
